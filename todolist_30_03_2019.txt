##########################          DONE         ###############################

Kasper:
- Find 1 or 2 different algorithms to implement (Check)
- Implement counter function of frames survived (Check)
- Implement function that saves the model after x number of epochs, so we can make smaller runs (Check)

Sasha:
- Find 1 or 2 different algorithms to implement (Check)
- Implement a function that can specify the scenarios to test in (needs to adapt to number of keys allowed) (Check)

Hans:
- Find 1 or 2 different algorithms to implement (Check)
- Figure out a optimal reward function (it should work for different scenarios) (Check)
- Write about the process so far (introduction to project framework and scope of project) (Check)



###############################    To do list NEXT     ######################

Kasper:
- Read about A2C and start doom implementation 
- Get TensorBoard working
- Read through the A2C links on implementation provided by Kasper
- Run gdoom on Kaspers computer and get result into a tabel. Kills/Frames survived. 
- 

Sasha:
- Read about A2C and start doom implementation 
- Get TensorBoard working
- Action Matrix should be define in a way that action should be able to customised for each scenario ( Policy gradient) 
- Read through the A2C links on implementation provided by Kasper

Hans:
- Write sort teori on the Policy gradient
- Read about A2C and start doom implementation 
- Get TensorBoard working
- Read through the A2C links on implementation provided by Kasper
- Look into getting the groom environment to work on 3 scenarios. 
- 

28.03.2019
 •We decided to work with 1 main algorithms for now.
 •Reading aboutPolicy gradientsand finding literature and reference and previous implementation onthe policy gradient(together)
 •This week was dedicated to research these implementations.
 •Research ways to implement policy gradient into the Viz-doom environment and try and get a initialrun of the policy gradient in the Viz-doom environment (Oleksandr)
 
04.04.2019
Initial policy gradient algorithm script is running now we need to improve 
 Issues to solve:
 •Fix saver function, so the training can be carried out from the last saved point (Kasper)
 •Setting different rewards for individual actions, in order to maximize the total rewords(Tune how much point we lose by losing life, missing, killing a monster) (Olek)
 •Making it easy to change different scenarios by only changing one parameter (Hans)
 •Fix the actions. (Add other actions than turning right/left and shoot)Add: move left/right/forward/backward (Kasper)
 •Research further Algorithms that could implemented into the Viz-doom environment(Al)
 
 Week 8: 01.05.2019
 •Write the theory of the two algorithms in relation to our experiments into the Article (Hans)
 •Optimizing the loss function since the TensorBoard shows inconsistent result with the loss function and Amount of dead per episode(Olek)
 •Optimization on the neural network, parameters and loss function for the A3C - Be aware of the lossfunction and parameters setting should be the same for the policy gradient in order to be able tocompare the results. (Kasper
